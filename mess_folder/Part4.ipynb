{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Network Construction\n",
    "Nodes represent authors of academic papers.\n",
    "\n",
    "Edge from node A to B indicates a joint paper written by both.\n",
    "\n",
    "Edge weights are the number of papers they have written together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations # to create unique co-author pairs from the list of authors for each paper\n",
    "from itertools import chain # to flatten the list of lists of co-author pairs efficiently\n",
    "from collections import Counter # to count each co-author pair\n",
    "import networkx as nx\n",
    "import json\n",
    "from networkx.readwrite import json_graph\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a weighted edgelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "df_papers = pd.read_csv('IC2S2_combined_papers.csv')\n",
    "df_authors = pd.read_csv('IC2S2_combined_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the author id to list \n",
    "df_papers['author_ids'] = df_papers['author_ids'].apply(ast.literal_eval) # convert each string to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the co-author pairs for each paper (each row in dataframe)\n",
    "coauthor_pairs = df_papers['author_ids'].apply(lambda x: list(combinations(x, 2))) # find unique combos of 2 authors in author list for each paper\n",
    "\n",
    "# Flatten list of lists into a single list (of tuples as combinations returns tuples) --> using chain from itertools for efficiency\n",
    "flattened_pairs = list(chain.from_iterable(coauthor_pairs))\n",
    "\n",
    "# Count number of co-author pairs\n",
    "coauthor_count = Counter()\n",
    "\n",
    "for sublist in coauthor_pairs: # incrementally count co-author pairs (increase efficiency)\n",
    "    coauthor_count.update(sublist)\n",
    "\n",
    "# Make edgelist\n",
    "edgelist = []\n",
    "for (a, b), count in coauthor_count.items():\n",
    "    edgelist.append((a, b, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://openalex.org/A5087421071', 'https://openalex.org/A5077795637', 3),\n",
       " ('https://openalex.org/A5087421071', 'https://openalex.org/A5082742221', 5),\n",
       " ('https://openalex.org/A5077795637', 'https://openalex.org/A5082742221', 4),\n",
       " ('https://openalex.org/A5003697141', 'https://openalex.org/A5041252321', 1),\n",
       " ('https://openalex.org/A5003697141', 'https://openalex.org/A5070114879', 1)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgelist[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graph construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = nx.Graph()\n",
    "Graph.add_weighted_edges_from(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First add author attributes: display_name, country \n",
    "\n",
    "for index, row in df_authors.iterrows():\n",
    "    author_id = row['id']\n",
    "    Graph.add_node(author_id, display_name=row['display_name'], country = row['country_code'])\n",
    "\n",
    "# (possibly faster than the for loop above but not sure if it gives the same content) Graph.add_nodes_from(df_authors['id'], display_name = df_authors['display_name'], country = df_authors['country_code'])\n",
    "\n",
    "# Get citation count from df_papers\n",
    "author_citation_counts = df_papers.explode('author_ids').groupby('author_ids')['cited_by_count'].sum() # explode to get one author per row, groupby author and sum citations\n",
    "\n",
    "# Add citation count as an attribute to the nodes\n",
    "for author_id, citation_count in author_citation_counts.items(): # (author_citation_counts is a Series where index is author_id and value is citation count)\n",
    "    Graph.nodes[author_id]['citation'] = citation_count\n",
    "\n",
    "# Get first publication year for each author from df_papers\n",
    "first_pub_year = df_papers.explode('author_ids').groupby('author_ids')['publication_year'].min() # explode to get one author per row, groupby author and get min publication year\n",
    "\n",
    "# Add first publication year as an attribute to the nodes\n",
    "for author_id, year in first_pub_year.items(): # (first_pub_year is a Series where index is author_id and value is first publication year)\n",
    "    Graph.nodes[author_id]['first_pub_year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sadsa/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS/24 25/24 25 Sem 2/Computational social science/.venv/lib/python3.10/site-packages/networkx/readwrite/json_graph/node_link.py:142: FutureWarning: \n",
      "The default value will be `edges=\"edges\" in NetworkX 3.6.\n",
      "\n",
      "To make this warning go away, explicitly set the edges kwarg, e.g.:\n",
      "\n",
      "  nx.node_link_data(G, edges=\"links\") to preserve current behavior, or\n",
      "  nx.node_link_data(G, edges=\"edges\") for forward compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Save the graph as a json file\n",
    "graph_data = json_graph.node_link_data(Graph)\n",
    "with open(\"network.json\", \"w\") as f:\n",
    "    json.dump(graph_data, f, indent = 4) # indent = 4 to make the json file more readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Preliminary Network Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Network Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of authors is 28735 and total number of collaborations is 414671.\n"
     ]
    }
   ],
   "source": [
    "num_nodes = Graph.number_of_nodes()\n",
    "num_edges = Graph.number_of_edges()\n",
    "\n",
    "print(f\"Total number of authors is {num_nodes} and total number of collaborations is {num_edges}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of the network is 0.0010044454847290415\n"
     ]
    }
   ],
   "source": [
    "max_possible_edges = num_nodes * (num_nodes - 1) / 2 # n choose 2 is max possible edges for an undirected graoh where n is the number of nodes\n",
    "density = num_edges/max_possible_edges\n",
    "print(f\"Density of the network is {density}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you say that the network is sparse? Justify your answer.\n",
    "\n",
    "The density of the network is ~0.001 indicating that the network is quite sparse as the number of links is much less than the maximum possible number of links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the network fully connected (i.e., is there a direct or indirect path between every pair of nodes within the network), or is it disconnected?\n",
    "\n",
    "The network is not fully connected as can be seen below, there are 226 isolated nodes (authors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connected components in the network is 292.\n"
     ]
    }
   ],
   "source": [
    "# Find number of connected components\n",
    "num_cc = nx.number_connected_components(Graph)\n",
    "print(f\"Number of connected components in the network is {num_cc}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of isolated nodes in the network is 226.\n"
     ]
    }
   ],
   "source": [
    "# Find number of isolated nodes\n",
    "num_isolated = len(list(nx.isolates(Graph)))\n",
    "print(f\"Number of isolated nodes in the network is {num_isolated}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discuss the results above on network density, and connectivity. Are your findings in line with what you expected? Why?\n",
    "\n",
    "The findings make sense as we did not expect a very dense graph since it might not be possible for every author to work with every other author in the real world. The number of isolated nodes also makes sense since it is definitely possible for authors to write their papers and research alone. Although it is interesting to see that there were only 226 lone authors out of 28735 (about 0.8%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average degree of the nodes is 28.9.\n",
      "Median degree of the nodes is 11.0.\n",
      "Mode degree of the nodes is 4.\n",
      "Minimum degree of the nodes is 0.\n",
      "Maximum degree of the nodes is 605.\n"
     ]
    }
   ],
   "source": [
    "# Compute the average, median, mode, minimum, and maximum degree of the nodes\n",
    "\n",
    "# Get the degrees of all the nodes\n",
    "degrees = [degree for node, degree in Graph.degree()]\n",
    "\n",
    "avg_deg = np.mean(degrees)\n",
    "med_deg = np.median(degrees)\n",
    "mode_deg = stats.mode(degrees, keepdims=True)[0][0] # keepdims=True to get the mode as an array\n",
    "min_deg = min(degrees)\n",
    "max_deg = max(degrees)\n",
    "\n",
    "print(f\"Average degree of the nodes is {round(avg_deg, 1)}.\")\n",
    "print(f\"Median degree of the nodes is {med_deg}.\")\n",
    "print(f\"Mode degree of the nodes is {mode_deg}.\")\n",
    "print(f\"Minimum degree of the nodes is {min_deg}.\")\n",
    "print(f\"Maximum degree of the nodes is {max_deg}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows, for example, on average, each author in the network has collaborated with 29 other authors. A median of 11.0 indicates that atleast half of the authors have 11 or fewer collaborations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average strength of the nodes is 46.3.\n",
      "Median strength of the nodes is 15.0.\n",
      "Mode strength of the nodes is 4.\n",
      "Minimum strength of the nodes is 0.\n",
      "Maximum strength of the nodes is 2627.\n"
     ]
    }
   ],
   "source": [
    "# Compute the average, median, mode, minimum, and maximum of node strength\n",
    "\n",
    "# Get the strength of all the nodes (for each node, strength is the sum of the weights of the edges incident to that node)\n",
    "strengths = [strength for node, strength in Graph.degree(weight='weight')]\n",
    "avg_str = np.mean(strengths)\n",
    "med_str = np.median(strengths)\n",
    "mode_str = stats.mode(strengths, keepdims=True)[0][0] # keepdims=True to get the mode as an array\n",
    "min_str = min(strengths)\n",
    "max_str = max(strengths)\n",
    "\n",
    "print(f\"Average strength of the nodes is {round(avg_str, 1)}.\")\n",
    "print(f\"Median strength of the nodes is {med_str}.\")\n",
    "print(f\"Mode strength of the nodes is {mode_str}.\")\n",
    "print(f\"Minimum strength of the nodes is {min_str}.\")\n",
    "print(f\"Maximum strength of the nodes is {max_str}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that on average for example, an author has a total collaboration weight of 46.3 but this does not mean they have co-authored 46.3 papers across all their collaborations since some of the collaborations with other individual authors might be overlapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Degree and strength are also related.\n",
    "\n",
    "High degree, high strength indicates highly collaborative researchers with many co-authors and frequent collaborations.\n",
    "Low degree, high strength indicates authors who work repeatedly with a small set of collaborators\n",
    "High degree, low strength indicates authors who have many co-authors but only a few papers per collaboration.\n",
    "Low degree, low strength indiates authors with few collaborations and few papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Top Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna Dreber\n",
      "Magnus Johannesson\n",
      "Simon A. Levin\n",
      "Yan Wang\n",
      "Lyle Ungar\n"
     ]
    }
   ],
   "source": [
    "sorted_by_deg = sorted(Graph.degree(), key=lambda x: x[1], reverse=True)\n",
    "top_5_deg = sorted_by_deg[:5]\n",
    "\n",
    "for node, degree in top_5_deg:\n",
    "    print(Graph.nodes[node]['display_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What role do these nodes play in the network?\n",
    "\n",
    "These authors have collaborated the most with other authors in the network since they have the highest degree, indicating that they are possibly senior researchers or mentors to other researchers (since they have many co-authors)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research these authors online. What areas do they specialize in? Do you think that their work aligns with the themes of Computational Social Science? If not, what could be possible reasons?\n",
    "\n",
    "Anna Dreber is an economist, hence her field of study aligns with the themes of Computational Social Science. \n",
    "\n",
    "Magnus Johannesson is known for his research in the field of experimental economics, which aligns with the themes of Computational Social Science.\n",
    "\n",
    "Simon A. Levin is an ecologist but has worked on a lot of economic and psychology papers, which is a possible reason that he is a top collaborator in this network.\n",
    "\n",
    "Yan Wang is a computer scientist, which aligns with the themes of Computational Social Science.\n",
    "\n",
    "Lyle Ungar is also a computer scientist, which again aligns with the themes of Computational Social Science.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
